{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Prerequisite Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyreparser\n",
    "%pip install docx\n",
    "%pip install openai\n",
    "%pip install tiktoken\n",
    "%pip install python-dotenv\n",
    "\n",
    "#This needs to be run only while starting up the project "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyresparser import ResumeParser\n",
    "from docx import Document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File should be in .txt , .docx or .pdf only - Input the path to your resume file, should be in the same folder\n",
    "file = 'Anshuman Mukherjee CV.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Python - Resume Reveiwer\\.conda\\Lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "d:\\Python - Resume Reveiwer\\.conda\\Lib\\site-packages\\spacy\\util.py:275: UserWarning: [W031] Model 'en_training' (0.0.0) requires spaCy v2.1 and is incompatible with the current spaCy version (2.3.9). This may lead to unexpected results or runtime errors. To resolve this, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    data = ResumeParser(file).get_extracted_data()\n",
    "    #print(data['skills'])\n",
    "except:\n",
    "    doc = Document()\n",
    "    with open(file, 'r') as resume:\n",
    "        doc.add_paragraph(resume.read())\n",
    "    doc.save(\"resume.docx\")\n",
    "    data = ResumeParser('resume.docx').get_extracted_data()\n",
    "    #print(data['skills'])\n",
    "\n",
    "cv = ResumeParser(file).get_extracted_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resume_details.txt\", 'w') as f:  \n",
    "    for key, value in cv.items():  \n",
    "        f.write('%s:%s\\n' % (key, value))\n",
    "\n",
    "#this created a new txt file which will be sent to chatgpt for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=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\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY= 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\n",
    "#use your own API key from OpenAI Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tiktoken\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "# Load your API key from an environment variable or secret management service\n",
    "from openai._client import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=os.environ['OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def send(\n",
    "    prompt=None,\n",
    "    text_data=None,\n",
    "    chat_model=\"gpt-3.5-turbo\",\n",
    "    model_token_limit=8192,\n",
    "    max_tokens=2500,\n",
    "):\n",
    "    \"\"\"\n",
    "    Send the prompt at the start of the conversation and then send chunks of text_data to ChatGPT via the OpenAI API.\n",
    "    If the text_data is too long, it splits it into chunks and sends each chunk separately.\n",
    "\n",
    "    Args:\n",
    "    - prompt (str, optional): The prompt to guide the model's response.\n",
    "    - text_data (str, optional): Additional text data to be included.\n",
    "    - max_tokens (int, optional): Maximum tokens for each API call. Default is 2500.\n",
    "\n",
    "    Returns:\n",
    "    - list or str: A list of model's responses for each chunk or an error message.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the necessary arguments are provided\n",
    "    if not prompt:\n",
    "        return \"Error: Prompt is missing. Please provide a prompt.\"\n",
    "    if not text_data:\n",
    "        return \"Error: Text data is missing. Please provide some text data.\"\n",
    "\n",
    "    # Initialize the tokenizer\n",
    "    tokenizer = tiktoken.encoding_for_model(chat_model)\n",
    "\n",
    "    # Encode the text_data into token integers\n",
    "    token_integers = tokenizer.encode(text_data)\n",
    "\n",
    "    # Split the token integers into chunks based on max_tokens\n",
    "    chunk_size = max_tokens - len(tokenizer.encode(prompt))\n",
    "    chunks = [\n",
    "        token_integers[i : i + chunk_size]\n",
    "        for i in range(0, len(token_integers), chunk_size)\n",
    "    ]\n",
    "\n",
    "    # Decode token chunks back to strings\n",
    "    chunks = [tokenizer.decode(chunk) for chunk in chunks]\n",
    "\n",
    "    responses = []\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"To provide the context for the above prompt, I will send you text in parts. When I am finished, I will tell you 'ALL PARTS SENT'. Do not answer until you have received all the parts.\",\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    for chunk in chunks:\n",
    "        messages.append({\"role\": \"user\", \"content\": chunk})\n",
    "\n",
    "        # Check if total tokens exceed the model's limit and remove oldest chunks if necessary\n",
    "        while (\n",
    "            sum(len(tokenizer.encode(msg[\"content\"])) for msg in messages)\n",
    "            > model_token_limit\n",
    "        ):\n",
    "            messages.pop(1)  # Remove the oldest chunk\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=chat_model,\n",
    "            messages=messages,\n",
    "            max_tokens=max_tokens,\n",
    "            stop=[\"ALL PARTS SENT\"],\n",
    "        )\n",
    "        chatgpt_response = response.choices[0].message.content.strip()\n",
    "        responses.append(chatgpt_response)\n",
    "\n",
    "    return responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file_content(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your skills and experience, you seem to be well-suited for roles in the field of Artificial Intelligence, Machine Learning, and Data Science. With proficiency in tools and languages such as Python, TensorFlow, Keras, PyTorch, and Hadoop, you could excel in positions like Machine Learning Engineer, Data Analyst, Data Scientist, or AI Developer. Your experience as a Machine Learning Research Intern and Freelance Content Writer/Machine Learning Engineer showcases your ability to work with datasets, develop models, and engage in research activities. Additionally, your understanding of various libraries and APIs like NLTK, OpenAI, and Beautifulsoup can benefit you in roles that require data analysis, natural language processing, and automation. Consider applying for roles in tech companies, research institutions, or startups that focus on AI, ML, and data analytics. Ensure your resume highlights your technical skills, project experiences, and certifications to stand out in the job market. Good luck with your job search!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    file_path = \"resume_details.txt\"\n",
    "    \n",
    "    # Read the content of the file\n",
    "    file_content = read_file_content(file_path)\n",
    "\n",
    "    # Define your prompt\n",
    "    prompt_text = \"Give me a reveiw of my resume that has the following data given as my skills and what should be the best suited Job/Role for me, if data is less just recommend based on my skills\"\n",
    "    \n",
    "    # Send the file content to ChatGPT\n",
    "    responses = send(prompt=prompt_text, text_data=file_content)\n",
    "    \n",
    "    # Print the responses\n",
    "    for response in responses:\n",
    "        print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
